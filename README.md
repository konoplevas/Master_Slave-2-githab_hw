### Активный master-сервер и пассивный репликационный slave-сервер

**Преимущества:**
- **Отказоустойчивость** - при падении master-сервера slave может взять на себя его функции
- **Резервное копирование** - slave-сервер может использоваться для бэкапов без нагрузки на master
- **Чтение без блокировок** - можно направлять запросы на чтение на slave, разгружая master
- **Тестирование** - на slave можно тестировать обновления и изменения перед применением на master
- **Простота настройки** - относительно простая архитектура для реализации

### Master-сервер и несколько slave-серверов

**Преимущества:**
- **Масштабируемость чтения** - возможность распределять нагрузку чтения между несколькими slave-серверами
- **Геораспределение** - slave-серверы можно размещать в разных регионах для уменьшения задержек
- **Балансировка нагрузки** - равномерное распределение запросов на чтение
- **Повышенная отказоустойчивость** - при выходе из строя одного slave-сервера система продолжает работать
- **Специализация** - разные slave-серверы можно настроить для разных типов запросов

## Задание 2: План горизонтального и вертикального шардинга

### Архитектура системы

**Вертикальный шардинг:**
- Разделение таблиц по разным серверам на основе функциональности
- **Сервер A**: пользователи (таблицы users, user_profiles, user_sessions)
- **Сервер B**: книги (таблицы books, authors, genres)
- **Сервер C**: магазины (таблицы shops, inventory, orders)

**Горизонтальный шардинг:**
- Разделение данных внутри таблиц по ключам шардинга
- Пользователи: шардинг по user_id (range-based)
- Книги: шардинг по genre_id (hash-based)
- Магазины: шардинг по region_id (geographic)

### Блоксхема архитектуры
┌─────────────────┐
│ Load Balancer │
└─────────────────┘
│
├─────────────────┬─────────────────┐
│ │ │
┌────────▼────────┐ ┌──────▼──────┐ ┌────────▼────────┐
│ Users Shard 1 │ │ Books Shard │ │ Shops Shard │
│ (ID: 1-1000) │ │ Cluster │ │ Cluster │
└─────────────────┘ └─────────────┘ └────────────────┘
│ │ │
┌────────▼────────┐ ┌──────▼──────┐ ┌────────▼────────┐
│ Users Shard 2 │ │ Books Shard │ │ Shops Shard │
│ (ID: 1001-2000)│ │ Cluster │ │ Cluster │
└─────────────────┘ └─────────────┘ └────────────────┘
### Режимы работы серверов

- **Master-серверы**: READ/WRITE операции для каждого шарда
- **Slave-серверы**: READ-ONLY реплики для каждого мастера
- **Координатор шардинга**: отвечает за маршрутизацию запросов
- **Балансировщик нагрузки**: распределяет запросы между шардами

### Принципы построения системы

1. **Вертикальное разделение**:
   - Каждая бизнес-сущность находится на отдельном сервере
   - Уменьшение конкуренции за ресурсы между разными типами данных
   - Оптимизация схемы БД под конкретную предметную область

2. **Горизонтальное разделение**:
   - Данные распределяются по диапазонам (range) или хэшу (hash)
   - Равномерное распределение нагрузки между шардами
   - Возможность линейного масштабирования

3. **Репликация**:
   - Каждый шард имеет master для записи и slave для чтения
   - Обеспечение отказоустойчивости и высокой доступности
   - Разделение операций чтения и записи
## Задание 3*: Настройка шардинга

### Описание проекта
Данный проект демонстрирует настройку горизонтального и вертикального шардинга базы данных с использованием MySQL и репликации Master-Slave.

### Архитектура
- **Вертикальный шардинг**: Разделение по функциональности (пользователи, книги, магазины)
- **Горизонтальный шардинг**: Разделение данных внутри таблиц
- **Master-Slave репликация**: Обеспечение отказоустойчивости и масштабируемости чтения

### Запуск системы

#### Требования
- Docker
- Docker Compose

#### Запуск
```bash
docker-compose up -d
Структура базы данных
Шард 1: Пользователи (порт 3307)
Таблицы: users, user_profiles

Диапазон: user_id 1-1000000

Шард 2: Книги (порт 3309)
Таблицы: books, authors, genres

Хэш-шардинг по genre_id

Шард 3: Магазины (порт 3311)
Таблицы: shops, inventory, orders

Географический шардинг по region_id

Настройка репликации
Каждый мастер-сервер имеет соответствующего slave-сервера для репликации:

Shard1 Slave: порт 3308

Shard2 Slave: порт 3310

Shard3 Slave: порт 3312
ProxySQL
ProxySQL настроен на порту 6033 для маршрутизации запросов между шардами.


Master_Slave-2-githab_hw/
├── docker-compose.yml
├── config/
│   ├── init-master.sql
│   ├── init-slave.sql
│   ├── sharding-config.sql
│   └── proxysql.cnf
├── scripts/
│   └── setup-sharding.sql
└── README.md
Использование
Запустите все контейнеры: docker-compose up -d

Проверьте статус репликации на slave-серверах

Настройте приложение для использования ProxySQL на порту 6033

Тестируйте распределение запросов между шардами

Мониторинг
Для мониторинга состояния репликации используйте:

sql
SHOW SLAVE STATUS\G
Для проверки распределения данных между шардами используйте метаданные в базе shard_metadata.
